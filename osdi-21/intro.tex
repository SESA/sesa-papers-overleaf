\section{Introduction}
\textbf{Power is an instantaneous quantity, and cannot be consumed or saved, *energy* can be.}
Tuning the energy consumption of servers in data centers is critical. Reducing the power consumption of each of 10,000 servers by 10 Watts (10 Joules/second) could power approximately 100 US households with a corresponding savings of \$100,000/year \textbf{(provide details of calculation)}. This is further exacerbated by the increasingly constrained energy budgets of data centers~\cite{SmoothOperator, Dynamo}. The factors that affect a servers' energy use arises, however, from the complex interactions between the workload, software components and the hardware of the system itself. 

\indent One common approach to improve energy efficiency of datacenter workloads is to tune a node's power consumption down by using features on modern processors to modulate power consumption of CPUs, namely Running Average Power Limit (RAPL)~\cite{intel_rapl} and Dynamic Voltage Frequency Scaling (DVFS) ~\cite{cpufreq_governor}~\cite{10.1145/2678373.2665718, 10.1145/2806777.2806848}. However, most of these approaches only focus on a single application of the processor frequency or power limiting features. We are interested in how both feature interplays with each other on networked workloads. Further, we introduce a third parameter, namely the interrupt delay mechanism that exist on modern NICs.

% this seems wrong to me... this is making the paper very complicated
% we need to focus on a clear simply novelty
%.
% Tuning for energy matters in the datacenter
%. Given the large amount of resources and stable demand providers often dedicate hardware to running single long lived services that make up their cloud platform.  
%.   Ideally given a stack of software and a hardware node a provider would like to configure the hardware parameters of the node such that the energy t consumed to provide the service is minimized.  Of co

%. While their is considerable research into the impact of tuning parameters of the hardware on user mode compute bound work there little evidence that hardware turning for IO bound cloud services which spend significant time within the operating system software.   
%  In this paper we study the impact that the operating system can have on task of tuning energ.  



\indent \textbf{Questions}
\begin{itemize}
    \item How does RAPL, DVFS, ITR impact a variety of network workloads: NetPIPE, NodeJS, Memcached, Memcached+Silo in Linux?
    \item \textit{vvvvvvvvvvvvvvvvvvvv} in EbbRT?
    \item Which of these hardware knobs have more of an impact?
    \item How does the different system structure in EbbRT vs Linux affect the impact of these hardware knobs?
    \item \textbf{Main Point 1} Hardware tuning matters (probably redundant point given results shown by prior works)
    \item \textbf{Main Point 2} Even in a more efficient unikernel, hardware tuning still matters and we are able to further lower energy usage.
\end{itemize}

%%However, it has been shown that just tuning hardware settings such as network card interrupt delay values, processor frequency, sleep states, processor package power limits etc. can result in energy savings given some workload and software configuration~\cite{a,b,c}. This raises a natural question: what impact does tuning the operating system (OS) alone have on energy tuning? Can an isolated change in OS structure enable lower energy consumption? Specifically, are simpler operating systems like unikernels, a better base for minimizing energy consumption compared to a general purpose OS given a fixed workload requirement?

An abundance of computing resources, in the data centers that power the cloud, and sustained stable application demand has led to systems being dedicated to running a single task.   Where the systems are complete physical machines (bare-metal) or partitions of a physical machine constructed through virtualization (virtual).  The tasks maybe long-lived and infrastructure in nature, such as MemCached instances,  or shorted-lived and transient such as Node.js instances executing a user defined and invoked serverless function. 

 The use of Unikernels, stripped down and simplified operating systems software structured and customized to running a single task, has been proposed to reduce overheard and improve performance.  Research has demonstrated that shedding various complex mechanisms and policies of a general purpose OS, which are developed in the context of multiplexing and sharing of resources across untrusted tasks, can result in significant improvements. 
  % Uni-kernels, successfully exploit simplified runtime organizations and processing models customized to the single task being run. 
 %Example simplifications include colocating user and system functionality in a single protection domain and run-to-completion unified protocol and application processing on interrupts. It is natural to consider if and to what extent unikernel structure can be used as a primitive to optimizing energy efficiency.  
   
 In this paper we use EbbRT, a framework for constructing task specific uni-kernels to compare and contrast the effectiveness of tuning energy efficiency with respect to Linux.  When running the FaceBook ETC Memcached workload EbbRT can be tuned using processor and NIC parameters to consume 1/3 less energy in contrast to minimum energy consumption we could achieve when tuning the same parameters when using Linux.  We find that there are two core components to these results; 1) the EbbRT software stack achieves a two fold improvement in instruction efficiency and 2) its dedicated and simplified processing policies permit tuning to result in a 20\% greater fraction of time spent in hardware low-power states.  On the hardware we use for our evaluation in the extreme we observed a reduction in power consumption of 40 Watts while maintaining for a requisite Quality of Service (QoS).  Considering the scale of a Data Center, the saving associated with adopting 	an alternative OS structure could have significant economic and environmental impact.  
   
   
   
      

