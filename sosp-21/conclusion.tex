\section{Concluding remarks}

% outline:
%  say briefly what paper did
%  high level results and contributions
%  say unique in fine grained detail 
%  while it is probably obvious, nobody has characterized unikernels
%  conclusions from those resul

We adopt EDP as a metric to improve energy efficiency of network intensive data center workloads. We instrumented code in network device driver to collect packet and hardware statistics at one millisecond granularity. 
We statically tune three hardware parameters DVFS, RAPL and interrupt delay to optimize the EDP for three workloads on both Linux and a library OS. We compared our results to Linux has its dynamic policies enabled. Across the three workloads, we consistently find statically configuring the hardware parameters achieves substantially overall efficiency {\em and} energy efficiency than the dynamic control in default Linux.
%and contrast those statically configured systems to Linux using its normal dynamic heuristics to control those parameters. 

%We find quite consistent results across the four workloads.  First, it turns out that 



%While this is not totally surprising that statically configuring a system that is offering. fixed functionality results in improvements, the degree of improvement is surprising. 
%%In the tuning of Linux we simply turned off its dyanmic control of the hardware mecahnisms, but did not change any of its other dynamic policies.  
%We further found that a special purpose library OS, with no explicit tuning for power, achieve even better energy efficiency.
%To our knowledge we are the first to quantify the impact of using library OS software on energy.

%The study is unique in adopting a very fine grained measurement approach that provides us with insgiht into the behavior of these systems. 
We find that Linux's dynamic policies result in it executing requests rapidly to enable it to quickly go into an efficient deep sleep.
On the other hand, when we statically tune Linux, depending on the demand, it 
can adopt a more efficient mode, finishing the overall work faster and save more energy over Linux default.

%.  That is, it can race to halt on a overall workload rather than in a fine grained fashion.
We are the first to quantify the impact of using baremetal library OS on energy by collecting fine-grained per interrupt statistics of using both packet processing and hardware counters.  We find that the library OS uses fewer instruction to complete the work and that this has impact on the energy consumed.  This largely translates into getting more application level work done in fewer instruction.  High speed data center networks put the OS and protocol stack processing code on the hot path. Using fewer instructions (and attendant drop in busy cycles) to complete the application work leads to two energy consumption benefits; 1) it reduces the base energy cost to complete the work, and 2) it creates greater opportunities to halt the processor between network transactions.  The later benefit makes it possible to achieve a simple "race to halt" behaviour across epochs of network activity and enables going into processor sleep states. We also find that across all our applications, the simplified and naive policies of the library OS leads to taking advantage of faster sleep state transitions while also achieving higher performance. This is due in part to the library OSes packet processing efficiency to get work done quickly and therefore go into a deep sleep state.

%We are the first to explore the impact of a baremetal library OS design on energy efficiency.   We find that as expected the library OS uses fewer instruction to complete the work and that this has impact on the energy consumed.  This largely translates into getting more application level work done in fewer instruction and this matters despite the heavy IO nature of the workloads.  This is in part due to the nature of high speed networking.  High speed data center networks put OS device and protocol processing code on the hot path -- in some sense making the workload actually more compute bound that one might expect.  Using fewer instructions (and attendant drop in busy cycles) to complete the application work leads to two energy consumption benefits; 1) it reduces the base energy cost to complete the work, and 2) it creates greater opportunities to halt the processor between network transactions.  Essentially this enables the library OS to "race to halt" on both an overall workload and per-interrupt basis. 

%Across all our workloads, the simplified and naive policies of the library OS, afforded by not needing to run or arbitrate multiple applications, leads to exploiting deeper sleep states while also achieving higher performance.  In EbbRT, when an interrupt occurs, like other library OS it implements a default run to completion model, by disabling interrupts.  When there are no work,  pending interrupts or packets dequeued from prior interrupts to process, EbbRT simply halts the processor to the deepest available sleep state. In contrast, even though we disable Linux's mechanisms for setting the parameters there are other complex algorithms and policies that affect its behaviour.  For example it implements a complex algorithm for enacting a hybrid polling versus interrupt processing across network devices and has a subtle infrastructure for deciding what sleep state should be used for halting the processor based on estimation of when the next interrupt will occur from any source.  This all contributes to a complex dynamic behavior with respect to when the system should halt and if it does halt what sleep state will be requested.  We observer that even after we use fixed values for the three  hardware setting considered the other complex behaviours of Linux limits the ability to tune its combined energy and performance compared to EbbRT.

This work suggests that, for the fixed function cloud services that dominate today's data centers, externally controlled fixed policies can be much more effective than the complex dynamic policies our operating system's employ today.  It also suggest that there is enormous utility in exploring how we can adopt fixed policies and customized implementations for single applications. While library OSes are one way of catering to a single dedicated application it may be possible to integrate such support into a general purpose OS by adding a new "single app" kernel configuration that disables or sheds run-time complexity and dynamic behaviors to obtain the same benefits we observe.  

The control knobs we tune are external to the OS and result in significant savings. This suggests that statistical learning techniques, especially reinforcement learning methods, would be effective to learn policies geared for specific applications.
